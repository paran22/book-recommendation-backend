{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.19.11)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: trl in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.17.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.2.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from trl) (1.6.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.16)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wandb datasets transformers trl torch peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3812ac3cc50843f8b621ccc20ff9dce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/899 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c22c8201ae24fa3ab31a062087f05c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76ff67fd244439ebe61aa85d6a62884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae1173d381f49b3b33aed35862829cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6438414d2143408b8b3357d687c12714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e827034726461fbfedfa090303e3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c77993095764014bc145f83d07b280b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c47dc89b83d4a709a1518f7310dedea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델과 토크나이저 로드\n",
    "model_name = \"google/gemma-3-1b-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 크기: 108\n",
      "학습 데이터 크기: 86\n",
      "테스트 데이터 크기: 22\n",
      "\n",
      "=== 학습 데이터 예시 ===\n",
      "{'input': '감정: 외로움 / 원하는 효과: 공감받고 싶다 / 직업: 프리랜서 / 현재 상황: 잠들기 전 휴식 / 집중도: 가볍게 읽을 수 있는 책', 'instruction': '외로움을 공감하며 위로받을 수 있는 3권을 선정, 추천 이유와 효과를 각각 기술하세요.', 'output': '1. 외로움의 습격 - 김만권\\n\\n* 추천 이유: 외로움의 본질과 현실을 있는 그대로 바라보고, 저자의 통찰과 사례를 통해 공감을 느낄 수 있습니다.\\n* 이 책이 도움이 될 수 있는 이유: 외로움이 정상이자 성장의 동기가 될 수 있음을 일깨워줍니다.\\n\\n2. 혼자가 좋지만 고독사는 걱정입니다 - 몬가 미오코\\n\\n* 추천 이유: 혼자 사는 삶에 대한 여러 고민을 담아 유연하게 받아들이는 힘을 선사합니다.\\n* 이 책이 도움이 될 수 있는 이유: 혼자와 고독에 대한 두려움을 덜고, 자신만의 행복을 느낄 수 있습니다.\\n\\n3. (쇼펜하우어의) 고독한 행복 - 아르투어 쇼펜하우어\\n\\n* 추천 이유: 철학자의 시선을 통해 고독을 긍정적인 감정으로 전환하고 싶을 때 적합합니다.\\n* 이 책이 도움이 될 수 있는 이유: 철학적 사유와 실질적인 삶의 지혜를 함께 얻을 수 있습니다.'}\n",
      "\n",
      "=== 테스트 데이터 예시 ===\n",
      "{'input': '감정: 만족 / 원하는 효과: 새로운 시각과 영감 / 직업: 학생 / 상황: 주말 / 집중도: 깊이 몰입할 수 있는 책', 'instruction': '아래 상황에 맞는 3권을 선정, 추천 이유와 감정적 효과를 포함하여 작성.', 'output': '1. 각본 없음 - 아비 모건\\n\\n* 추천 이유: 단순한 이야기가 아닌 인생의 우연성과 변화를 직시할 수 있는 힘을 줍니다.\\n* 이 책이 도움이 될 수 있는 이유: 자신의 삶을 주체적으로 바라보고 긍정하는 영감의 시간이 됩니다.\\n\\n2. 공감사회를 위한 담론들 - 강황선\\n\\n* 추천 이유: 사회학적 관점에서 세상과 인간관계를 이해하는 데 도움이 됩니다.\\n* 이 책이 도움이 될 수 있는 이유: 새로운 관점을 습득하고 자아와 사회를 넓은 시야로 바라보게 해줍니다.\\n\\n3. 생각의 기술 - 코디정\\n\\n* 추천 이유: 논리의 틀을 갖추고 스스로 문제를 바라보는 방법을 안내합니다.\\n* 이 책이 도움이 될 수 있는 이유: 자기 주도적 사고와 문제해결력을 높이는 계기가 됩니다.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# corpus.json 파일 읽기\n",
    "with open('./data/corpus.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# train/test 분리 (80:20 비율)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"전체 데이터 크기: {len(data)}\")\n",
    "print(f\"학습 데이터 크기: {len(train_data)}\")\n",
    "print(f\"테스트 데이터 크기: {len(test_data)}\")\n",
    "\n",
    "# 데이터 예시 출력\n",
    "print(\"\\n=== 학습 데이터 예시 ===\")\n",
    "print(train_data[0])\n",
    "print(\"\\n=== 테스트 데이터 예시 ===\")\n",
    "print(test_data[0])\n",
    "\n",
    "# 리스트를 Dataset 형식으로 변환\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "test_dataset = Dataset.from_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 포매팅 함수 정의\n",
    "def formatting_func(example):\n",
    "    # instruction, input, output이 단일 문자열인 경우를 처리\n",
    "    instruction = example['instruction']\n",
    "    input_text = example['input'].strip() if example['input'] else \"\"\n",
    "    output = example['output']\n",
    "\n",
    "    # 형식화된 프롬프트 생성\n",
    "    text = f\"[Instruction]\\n{instruction.strip()}\\n\\n\"\n",
    "    if input_text:\n",
    "        text += f\"[Input]\\n{input_text}\\n\\n\"\n",
    "    text += f\"[Output]\\n{output.strip()}\"\n",
    "\n",
    "    return text\n",
    "\n",
    "# 데이터 콜레이터 설정\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Causal Language Modeling을 위해 False로 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gpt-finetuning</strong> at: <a href='https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation/runs/64prwhxs' target=\"_blank\">https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation/runs/64prwhxs</a><br> View project at: <a href='https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation' target=\"_blank\">https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250521_153428-64prwhxs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gimga-eun/Prac/book-recommandation/backend/wandb/run-20250521_153449-8gn6ansr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation/runs/8gn6ansr' target=\"_blank\">gpt-finetuning</a></strong> to <a href='https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation' target=\"_blank\">https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation/runs/8gn6ansr' target=\"_blank\">https://wandb.ai/knospe1-gaeun/Hanghae99-book-recommandation/runs/8gn6ansr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743ea628f9ab422ca3e855b5e093083d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to train dataset:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56dbd45aa3f478da863a4c842abdeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b707ea4590472982883b2ee6dd09c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a2c303d49f4811b38a31af105a61b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d03301239a448d901dd61b742b3dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/86 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240502d9fb754b7b86a9af2c9a29b4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying formatting function to eval dataset:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d4d656b6c446a9de38fc788ee6da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112a49f46715413a8db3f9e6b15dcb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ff142791cc493b97d70c5ea817fe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac72bd4f14e448c926d8c71472a20b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/33 : < :, Epoch 0.09/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='Hanghae99-book-recommandation',\n",
    "    name=f'gpt-finetuning',\n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    args=SFTConfig(\n",
    "        output_dir=f\"/tmp/clm-instruction-tuning\",\n",
    "        max_seq_length=128,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=100,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2e-5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\"\n",
    "    ),\n",
    "    formatting_func=formatting_func,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "\n",
    "trainer.save_model()\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
